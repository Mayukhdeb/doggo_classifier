{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vR_zXOnPRN8S"
   },
   "source": [
    "Mounting to drive and importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6gB8KpHT4Mf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNAhqjZkUb7I"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "                                                  #  '''  do not forget =    it's (HEIGHT, WIDTH)    ''' \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "torch.set_grad_enabled(True)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "   \n",
    "np.set_printoptions(threshold=50)    # 50 lines \n",
    "\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from numpy import random \n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter1d   ## smoother\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9phR2wNRVUX"
   },
   "source": [
    "Load Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Sa5mzcerPS6"
   },
   "outputs": [],
   "source": [
    "arr = np.array(np.load(\"/content/drive/My Drive/kaggle/doggonet/final_balanced_300_big.npy\", allow_pickle = True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuEfdZRiRa6C"
   },
   "source": [
    "Check whether all the labels have an equal number of instances and plot in a curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR99kBfJUizV"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "doo = arr[arr[:,1].argsort()]  ## alphabetically sort wrt column 1 \n",
    "\n",
    "\n",
    "print(doo[0])   # show first element \n",
    "\n",
    "def find_no_occ(arr, element):   ## \n",
    "    \n",
    "    co = 0 \n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        \n",
    "        if arr[i][1] == element:\n",
    "            co += 1\n",
    "            \n",
    "    return(co)\n",
    "\n",
    "\n",
    "\n",
    "def check_for_balance(arr):\n",
    "    \n",
    "    dist = []\n",
    "    \n",
    "    for m in range(len(arr)):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if arr[m][1] != arr[m-1][1]:\n",
    "            \n",
    "            no_occ = find_no_occ(arr, arr[m][1])\n",
    "    \n",
    "            dist.append(no_occ)\n",
    "        \n",
    "            \n",
    "    plt.plot(dist)\n",
    "    plt.show()\n",
    "    \n",
    "check_for_balance(doo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVxNm6ZXR0CF"
   },
   "source": [
    "Split loaded numpy array into columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6XXId-NZfl6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_column(arr, index):\n",
    "\n",
    "    x_train = []\n",
    "    for m in range (len(arr)):\n",
    "\n",
    "        x_train.append(arr[m][index])\n",
    "\n",
    "    return( np.array(x_train))\n",
    "\n",
    "  \n",
    "x_train = extract_column(arr,0)\n",
    "\n",
    "y_train = extract_column(arr,1)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kr7wnlvSR6c2"
   },
   "source": [
    "Using the `TensorDataset()` class wrapper \n",
    "\n",
    "And splitting the dataset into training and validation set on a 90 : 10 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kynIdbKRYkxM"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "\n",
    "\n",
    "full_dataset = TensorDataset(x_train_tensor, y_train_tensor)       ## make compatible with DataLoader \n",
    "\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))  ## 80/20 split\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fi44MfQhzq_"
   },
   "source": [
    "Setting batch sizes of 120 and 12 for train and test set, the train set has 120 possible labels which are randomly shuffled, hence the batch size of 120 would (approximately) contain all the labels in a balanced manner \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XZCeI7gk4MH"
   },
   "outputs": [],
   "source": [
    "## using a dataloader \n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=120, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=test_dataset, batch_size=12, drop_last = True)\n",
    "\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fraKDPazG64"
   },
   "source": [
    "Some simple functions which come in handy when visualising data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFEAStQOUxIN"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "## test NN output\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vis_loss_multi(loss_arr,val_arr):\n",
    "  \n",
    "    plt.plot(loss_arr)\n",
    "    plt.plot(val_arr)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utxIzB9vzq9w"
   },
   "source": [
    "*Doggonet needs no introduction*\n",
    "\n",
    "4 2D convolutional layers and 3 linear layers with all the bells and whistles included in between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gs4jEbncbbmr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## doggonet \n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 30, 5)           \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3,3)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(30,30,5)\n",
    "        self.conv3 = nn.Conv2d(30,30,5)\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(30)    \n",
    "        \n",
    "        self.conv4 = nn.Conv2d(30,30,5)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(4320, 900) \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)  # drop\n",
    "        \n",
    "        self.fc2 = nn.Linear(900, 900)\n",
    "        self.fc3 = nn.Linear(900, 360)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3_bn_linear = nn.BatchNorm1d(360)    \n",
    "     \n",
    "        \n",
    "        \n",
    "        self.fc4 = nn.Linear(360, 120)   ## output \n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "                                                                        ##   F.relu\n",
    "        x = self.pool(x)\n",
    "     \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = (self.conv3(x))\n",
    "        \n",
    "        x = F.relu(self.conv3_bn(x))\n",
    "    \n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "                             \n",
    "        x = x.view(x.size(0), -1)\n",
    "               \n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "doggonet = Net()\n",
    "\n",
    "print(doggonet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRSLqaOY0g_J"
   },
   "source": [
    "`make_train_step():` a single batch passes through CNN and backpropagation occurs \n",
    "    \n",
    "    \n",
    "`train():` basically trains the NN for n_epochs \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yz-7ryw4fJKE"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_train_step(model, optimizer):\n",
    "\n",
    "    def train_step(x, y):\n",
    "\n",
    "        pred = model(x)\n",
    "        \n",
    "        \n",
    "        y = y.long()\n",
    "        \n",
    "        \n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        \n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print (\"|\", end = \"\")\n",
    "        return loss.item()\n",
    "      \n",
    "    return train_step\n",
    "\n",
    "\n",
    "model = doggonet\n",
    "\n",
    "learning_rate = 0.091\n",
    " \n",
    "optimizer = optim.SGD(doggonet.parameters(), learning_rate)                             #,momentum = 0.5, nesterov = True)  ## nesterov is true \n",
    "\n",
    "train_step = make_train_step(model, optimizer)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.9)  # lr decreases by 10% after every 2 epochs\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, epochs):\n",
    "  \n",
    "\n",
    "  for i in range(epochs):\n",
    "    \n",
    "    print(\"epoch = \", i+1)\n",
    "    \n",
    "    foo = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "    \n",
    "    print (\"current lr = \", foo)\n",
    "    print(\"                    |                                                                                                                                                        |\")   \n",
    "    print(\"training batches  --\", end = \"\")\n",
    "\n",
    "   \n",
    "    for x_batch, y_batch in train_loader:\n",
    "      \n",
    "        model.train()\n",
    "\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "\n",
    "        losses.append(loss)\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            y_val = y_val.long()\n",
    "\n",
    "            yhat = doggonet(x_val)  # pred \n",
    "            val_loss = F.cross_entropy(yhat, y_val)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "    \n",
    "    scheduler.step()   ## lr decay caller \n",
    "      \n",
    "    \n",
    "    batch_avg_loss = sum(losses[-120:])/120\n",
    "    print (\"\")\n",
    "    \n",
    "    print(\"epoch avg loss = \", batch_avg_loss)\n",
    "\n",
    "    print (\" on the validadtion set -- global\")\n",
    "    \n",
    "    validation_avg_loss = (sum(val_losses[-12:])/12)\n",
    "    \n",
    "    print (\" validation set avg loss in last epoch = \", validation_avg_loss)\n",
    "    \n",
    "    vis_loss_multi(losses,val_losses)\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "    print (\"training complete -------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CPRbilifqUN"
   },
   "outputs": [],
   "source": [
    "train(train_loader, 10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6-EanOY4Rsy"
   },
   "source": [
    "Save the trained nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT8JUIiHc5Ac"
   },
   "outputs": [],
   "source": [
    "nn_name = \"/content/drive/My Drive/kaggle/doggonet/models/\" + \"10_epochs_doggonet_batchwise.pth\"\n",
    "\n",
    "torch.save(doggonet, nn_name)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "new_nn_doggonet.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
